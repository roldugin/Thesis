%% We use `subfiles' package
\documentclass[preamble.tex]{subfiles}
\begin{document}

\pagebreak{}

\chapter{Imperative Code Generation}

In the previous chapter we discussed how a graph of array combinators is turned into imprative loops. We first showed a generic loop structure consisting of \[init], \[guard], \[body], \[yield], \[bottom] and \[done] blocks. These loop sections represented a skeleton which every combinator would populate with relevant statements that would eventually be merged into a single loop.

We then looked at the translation of several of such combinators into loop language and showed how the populated loop skeletons would be merged together into ``runnable'' loops. While the sections of the loops did resemble imperative style code with some assembly-style labels attached to them, it was never mentioned just what makes a loop ``runnable''. After all, the presented code did not look like anything one would or could write in Haskell.

In this chapter we will see how the \Loop language is used to generate runnable code. We will also give its translation to one of the possible backends (and the only one currently available). This backend is targeting (perhaps unexcitingly) Haskell source language, which means that the code generated is Haskell.


\section{Approaches to looping}

There are many ways a loop can be represented in code. In the surface \LiveFusion language the loops are note explicit. However, most of the array combinators eventually form part of loops expressed in the internal \Loop language. We have discussed this language at length in the previous chapter.

When it comes to expressing loops there is a fundamental difference between the vast majourity of general purpose languages (even functional ones) and Haskell. In procedural languages the loop statements are usually built onto the language. Down at the machine level when the program is compiled to \name{Assembly} code, these loops become a collection of instructions with a $label$ and $jump$ instructions to go to either the top of the loop body or break out of the loop.

The situation is very different in Haskell however. Haskell does not have an explicit constuct for loops. All looping is expressed in the form of recursion. \todo{Perhaps elaborate on this if you have time}

If we are to generate \Haskell code that loops over arrays we need a way to express the conceptual loops we outlined in the previous chapter as recursive functions in our generated code.


\section{Fast mutable arrays in Haskell}

The main data structure \LiveFusion is ultimately working with is an array. To achieve high performance we must be able to generate code that loops effectively over arrays in memory.

We have just established that the looping in Haskell is done through recursive functions. We will now look at how this can be applied to array computation.

The internal \Loop language has \|writeArray| statement which hints the need for \*mutable* arrays. The use of mutable values is not typical in \Haskell and is discouraged. However, for performance reasons there are mechanisms by which this can be done.

In \Haskell all variable are immutable by default. To achieve mutability one must leave the pure context and use one that supports mutable state. In Haskell this usually amounts to using \|IO| or \|ST| monads.

The \|IO| monad lets the programmer alter the global state of the program and perform any desired side-effecting computations. On the other hand, \|ST| monad only allows to work with mutable memory. The memory is thread-local and must be allocated inside the monad in order to be used. The return value from the \|ST| monad is the pure \Haskell value. Stateful computations performed inside the monad are not visible outside the monadic context. The compiler ensures that no mutable state escapes the \|ST| computation. This means that for all intents and puposes an \|ST| computation can be considered pure, despite the fact that it may use side-effects internally (usually for efficiency reasons).

Mutable arrays in \Haskell can be used from both inside \|IO| and \|ST| monads. There are several implementations that provide similar interfaces to fast mutable arrays. I used the \name{vector}\footnote{http://hackage.haskell.org/package/vector} package in my development, and its use in the examples in this chapter should be quite self-explanatory.\footnote{The choice of \name{vector} library is mostly due to historical reasons. It has been first implemented by Roman Leshchinskiy in the research group I belong to and is currently providing array functionality to \name{Data Parallel Haskell}, \name{Repa} and \name{Accelerate}, all of which originate from this group.\todo{Accelerate uses Vector?}} Since we do not require to do any side-effecting computations in our loops except allocating and working with memory, arrays in \|ST| monad will suffice for us.

\todo{Perhaps give a simple example of looping using vector if the translation code from Loop to Haskell is hard to understand.}


\section{Compiling \Loop language to \Haskell loops}

I will now present the translation of the \Loop EDSL to Haskell. The definition of \Loop language is given once again in Figure \ref{fig:7-loop-grammar}. We will go over the code generation for this language using a simple example. \todo{Describe example}


\begin{cfigure}{\label{fig:7-loop-grammar}\Loop language grammar.}
\input{loop-grammar.tex}
\end{cfigure}
\todo{Put the footnotetext on the same page where the grammar ends up}\footnotetext{For improved readability the unique integers are replaced with meaningful names in the code listings instead.}


\begin{minipage}{\linewidth}
\begin{hscode2}%
      {\label{lst:7-toPercentile-hs}Generated Haskell code for $toPercentile$ function}
entry :: [Dynamic] -> Dynamic
entry [!arr_xs] = toDyn (run (fd arr_xs))

run :: Vector Int -> Vector Int
run !arr_xs = runST (init_ys arr_xs)

init_ys !arr_xs
  = do let !ix_xs = 0;
       let !len_xs = lengthArray arr_xs;
       let !len_ys = len_xs;
       !arr_ys <- newArray len_ys;
       guard_ys arr_xs arr_ys len_xs ix_xs

guard_ys !arr_xs !arr_ys !len_xs !ix_xs
  = do let !pred_xs = (<) ix_xs len_xs;
       let !ix_ys = ix_xs;
       if pred_xs
        then do body_ys arr_xs arr_ys len_xs ix_xs ix_ys
        else done_ys arr_xs arr_ys len_xs ix_xs ix_ys

body_ys !arr_xs !arr_ys !len_xs !ix_xs !ix_ys
  = do let !elt_xs = readArray ix_xs arr_xs;
       let !f_ys = \a -> (*) a (fromInteger 100);
       let !elt_ys = f_ys elt_xs;
       write_ys arr_xs arr_ys len_xs ix_xs ix_ys elt_ys

write_ys !arr_xs !arr_ys !len_xs !ix_xs !ix_ys !elt_ys
  = do writeArray arr_ys ix_ys elt_ys;
       bottom_ys arr_xs arr_ys len_xs ix_xs ix_ys elt_ys

bottom_ys !arr_xs !arr_ys !len_xs !ix_xs !ix_ys !elt_ys
  = do let !one_xs = 1;
       let !ix_xs' = (+) ix_xs one_xs;
       guard_ys arr_xs arr_ys len_xs ix_xs'

done_ys !arr_xs !arr_ys !len_xs !ix_xs !ix_ys
  = do !result <- sliceArray arr_ys ix_ys;
       return result
\end{hscode2}
\end{minipage}


To demonstrate the workings of the code generator we will use the source program given in Figure \todo{ref}, it's internal representation in \Loop language in Figure \todo{ref} as well as the resulting \Haskell code in Figure \ref{lst:7-toPercentile-hs}.

\begin{description}

\item[Blocks and Gotos] \hfill \\
A \Loop is essentially a group of labelled code blocks with a predefined entry block. Every code block becomes its own function in the generated code. We see in the example that each code block like \[body] became $body$ function. Each code block has a unique identifier associated with it (in our case $ys$), which distinguishes it from similarly named blocks of any nested loops which may be present.

A \*block* becomes a \*function* in the generated code. Consequently, the \|goto| statements become *function calls*. Each \|goto| statement specifies which block to transfer the control to.

Blocks of the internal \Loop language do not explicitely specify what loop state they require or declare. A loop's state is implicit and global. As will be discussed later in Section \todo{ref} the state of the loop is passed as function arguments in the generated code. This is the reason for a large number of aguments to functions generated from blocks. The process for generating the arguments from loop variables will be outlined in Section \todo{ref}.


\item[Guards and Cases] \hfill \\
The \Loop language offers two conditional statements: \|guard| and \|case|. Given a boolean expression the \|case| statement tranfers control to one of the two specified blocks. A \|guard| is a simplified \|case| statement which only transfers control to a different block if the predicate is \*false*, but stays in the same block otherwise. The \|guard| is used to preemt execution of a block if a condition is not met.

Both \|case| and \|guard| are translated to \Haskell's \|if| expression in the generated code. It can be seen in the provided example, that the \[guard] block as well as the \[body] contain a \|guard|. The former performs the bounds check of the loop index while the latter is the guard of the \|filter| combinator.

% One important thing to note is that the \|case| and the \|guard| must come after all variable bindings and updates. Maybe give an example of (map . filter). But then it is unclear what to do with (map (1/) . filter (/= 0)) The eager evaluation will not short circuit the filter and the division will be performed.

\item[Variable initialisation and update] \hfill \\
In the \Loop language every local variable must be initialised before use. Since the language is currently untyped and relies on subsequent type inference and type checking in the generated code compiler, there are no explicit declarations. However, the \Loop code generator checks that every variable has exacly one binding spot inside the loop and that the control goes through that binding before the first use of the vaiable.

The bound variables can be mutable as well as immutable. In fact the \Loop language does not make a distinction between the two in the way they are initialised and used.

A variable \*binding* appears as a \*strict* \|let| binding in the generated \Haskell code. The exclamation marks, called \*bang patterns*, ensure that every bound variable is evaluated to WHNF and no thunks are created when evaluating the code. In most cases this is not neccessary since the subsequent strictness analysis determines most variables to be strict anyway. However there are cases, especially in the presence of @filter@ combinators, where forcing strict evaluation is required for maintaining high performance of the generated code. \todo{See if not seq'ing post-filter variables results in thunks}

Whenever a new variable binding is encountered in a block of the loop it is assumed to be a fresh variable and it shadows any previous bindings of that variable in the environment. In practice this is useful for the cases where the block is entered multiple times throughout loop execution. For example, the \[body] block binds variables @elt_xs@ and @elt_filt@ on every iteration. They are subsequently read in \[body] and \[yield] but are not required afterwards. A simple liveness analysis described in section \todo{ref} allows us to only pass those variables from \[body] to \[yield] and disregard them everywhere else.

The situation with mutable variable is slightly more complex. For example, the loop index @i_xs@ is bound like a regular variable in the \[init] block. However, once it has been \*assigned to* in \[bottom], it is given a fresh name @i'_xs@ in the generated code. This is because variable in \Haskell are immutable. While there are ways to have mutable variables in \|ST| or \|IO| monads, it is less efficient as discussed further in Section \todo{ref}.

During liveness analysis mutable variable are treated the same way as their immutable counterparts. Technically it is possible to have a mutable variable that lives during one loop iteration but is not carried over to the next iteration but the author have not yet seen a combinator that would require that.

\item[Array manipulation] \hfill \\

Array is the fundamental data structure the \Loop language works with. As such the array primitives are built right into the language: @readArray@, @writeArray@, @arrayLength@, @newArray@ and @sliceArray@. The implementation of the primitives is presented in Listing \ref{7-array-primitives}.

\begin{hscode2}%
      {\label{7-array-primitives}%
      Array primitives implementation in \Haskell backend.}
import Data.Vector.Unboxed as V
import Data.Vector.Unboxed.Mutable as MV
import Control.Monad.ST

arrayLength :: Unbox a => V.Vector a -> Int
arrayLength = V.length

readArray :: V.Unbox a => V.Vector a -> Int -> a
readArray = V.unsafeIndex

writeArray :: V.Unbox a => MV.MVector s a -> Int -> a -> ST s ()
writeArray = MV.unsafeWrite

newArray :: V.Unbox a => Int -> ST s (MV.MVector s a)
newArray = MV.new

sliceArray :: V.Unbox a => MV.MVector s a -> Int -> ST s (V.Vector a)
sliceArray vec len = V.unsafeFreeze $ MV.unsafeTake len vec
\end{hscode2}

\item[Returning the result] \hfill \\
...


\end{description}





\todo{The translation is presented formally in Figure}




\subsection{Unboxing}
\subsection{Passing arrays to the generated code}
\subsection{Generating Haskell code}

\subsection{Loop state}
\section{Internal optimisations}

\subsection{Liveness analysis}

There are two caveats of the \Haskell code generator in its current state:
\begin{itemize}
\item A variable can only be assigned to once in any given block
\item The new value won't be available until the control is transfered to a successor block
\end{itemize}

Both of the above are not fundamental limitations of either \Loop EDSL or the \Haskell backend. The arise for the fact that the liveness analysis works on per-block basis and not per-statement. This means that liveless analysis tries to determine which variables are expected to be in scope in a particular block, which are updated and which are passed onto subsequent blocks. However, it does not attempt to do the same for each statement.

So far neither of these limitations posed a problem since the loop structure itself is so modular. There is no apparent benefit of investing in a more granular per-statement liveness analysis. The generated \Haskell code is run through \GHC which itself has excellent liveness analysis and many other efficient compilation tactics. The proposed \LLVM backend is also likely to be able to optimise the code in its current form.


\subsection{Generating}


\subsection{Looping}
\begin{itemize}
\item There are many ways a loop can be represented in code
\item FPrs see it as a recursive function
\item Procedural programmers see it as a while or for C loop
\item Down at the machine level it is a chunk of code with a label and jump statement to the beginning of the loop (or alternatively out of the loop)
\item GPGPU
\item Vectorised instructions
\item When generating HsCode only rec fun, however want fast machine code in the end
\item Tail rec
\item Give example of what machine code it becomes
\item Thus need to make sure we always have tail rec
\end{itemize}

\section{Hell}

\begin{itemize}
\item haskell via TH (slow codegen, all native, TH is helpful, easy to gen code and parametrising functions, use the excellent GHC optimiser)
\item external (c) (slow codegen, fast exec, how to identify function correspondence, must act as compiler)
\item llvm (fast inmem gen, low level, must act as compiler in many ways)

\end {itemize}


\section{Haskell code generation}

\subsection{What do we need to generate}
\begin{itemize}
\item Loop code
\item A plugin template
\item Interface glue
\item Arg passing to and from - variadic functions, can't do without tricks
\item Lists of args + Unsafe coerce
\end{itemize}

\subsection{Efficient numeric computations in Haskell}
\begin{itemize}
\item Talk about haskell data structures (lists, arrays)
\item about boxed values
\item Prohibitive performance costs
\item Unboxed values
\end{itemize}

\subsection{Mutable vectors}
\begin{itemize}
\item Very low level access
\item Haskell vector or GHC.Prim
\item Largely the same underneath
\item Vector may be more intuitive
\item Offers many types of vectors and levels of access to them
\item Uses ST monad, to make sure...
\end{itemize}


\section{GHC provided optimisations}
\subsection{Tail recursion}
\begin{itemize}
\item Perhaps put the points from above here
\end{itemize}

\subsection{Strictness}
\begin{itemize}
\item What is it and why
\item Strictness analysis example
\item Where in our case it would fail
\item What to do: two things, the easiest is !
\end{itemize}

\subsection{Inlining}
\begin{itemize}
\item Funcall costs
\item Perhaps give an example with benchmark
\item LLVM helps?
\end{itemize}

\subsection{Unboxing}
\begin{itemize}
\item Give example
\item Rewrite \texttt{case i\# of I\# ->} which rewrites
\item (Might wanna merge with the section above)
\end{itemize}




\subsection{Compilation and loading}
\begin{itemize}
\item GHC API
\end{itemize} 


\section{Background}

\subsection{Passing loop state}

\begin{itemize}
\item We were passing explicit args
\item fast, GHC knows how to optimise away unused/dup variables (of which we have a lot)
\item STRef/IORefs - convenient but they are boxed and are not inlined even though are programs are strict
\item State monad. Build State monad on top of ST, use tuples for multiple state variables. It inlines and unboxes everything alright, but for some reason there remain lazy lets and continuation.
\item Arguably the cleanest approach to unboxed mutable state. Removes the limitation outlined in () whereby the updated value of the assigned variable won't be available in the same block it's assigned. It would also make the internal compilation process cleaner. Right now it needs to generate a fresh variable name for the updated variable and keep track of the variables updated in the current block.
\end{itemize}

\end{document}