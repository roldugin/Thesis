\input{preamble.tex}

\section{Imperative Code Generation}

In the previous chapter we discussed how a graph of array combinators is turned into imprative loops. We first showed a generic loop structure consisting of \[init], \[guard], \[body], \[yield], \[bottom] and \[done] blocks. These loop sections represented a skeleton which every combinator would populate with relevant statements that would eventually be merged into a single loop.

We then looked at the translation of several of such combinators into loop language and showed how the populated loop skeletons would be merged together into ``runnable'' loops. While the sections of the loops did resemble imperative style code with some assembly-style labels attached to them, it was never mentioned just what makes a loop ``runnable''. After all, the presented code did not look like anything one would or could write in Haskell.

In this chapter we will see how the \Loop language is used to generate runnable code. We will also give its translation to one of the possible backends (and the only one currently available). This backend is targeting (perhaps unexcitingly) Haskell source language, which means that the code generated is Haskell.


\subsection{Approaches to looping}

There are many ways a loop can be represented in code. In the surface \LiveFusion language the loops are note explicit. However, most of the array combinators eventually form part of loops expressed in the internal \Loop language. We have discussed this language at length in the previous chapter.

When it comes to expressing loops there is a fundamental difference between the vast majourity of general purpose languages (even functional ones) and Haskell. In procedural languages the loop statements are usually built onto the language. Down at the machine level when the program is compiled to \name{Assembly} code, these loops become a collection of instructions with a \*label* and \*jump* instructions to go to either the top of the loop body or break out of the loop.

The situation is very different in Haskell however. Haskell does not have an explicit constuct for loops. All looping is expressed in the form of recursion. \todo{Perhaps elaborate on this if you have time}

If we are to generate \Haskell code that loops over arrays we need a way to express the conceptual loops we outlined in the previous chapter as recursive functions in our generated code.


\subsection{High performance looping in Haskell}

The main data structure \LiveFusion is ultimately working with is an array. To achieve high performance we must be able to generate code that loops effectively over arrays in memory.

We have just established that the looping in Haskell is done through recursive functions. We will now look at how this can be applied to array computation.

The internal \Loop language has \|writeArray| statement which hints the need for \*mutable* arrays. The use of mutable values is not typical in \Haskell and is discouraged. However, for performance reasons there are mechanisms by which this can be done.

In \Haskell all variable are immutable by default. To achieve mutability one must leave the pure context and use one that supports mutable state. In Haskell this usually amounts to using \|IO| or \|ST| monads.

The \|IO| monad lets the programmer alter the global state of the program and perform any desired side-effecting computations. On the other hand, \|ST| monad only allows to work with mutable memory. The memory is thread-local and must be allocated inside the monad in order to be used. The return value from the \|ST| monad is the pure \Haskell value. Stateful computations performed inside the monad are not visible outside the monadic context. The compiler ensures that no mutable state escapes the \|ST| computation. This means that for all intents and puposes an \|ST| computation can be considered pure, despite the fact that it may use side-effects internally (usually for efficiency reasons).

Mutable arrays in \Haskell can be used from both inside \|IO| and \|ST| monads. There are several implementations that provide similar interfaces to fast mutable arrays. I used the \name{vector}\footnote{http://hackage.haskell.org/package/vector} package in my development, and its use in the examples in this chapter should be quite self-explanatory.\footnote{The choice of \name{vector} library is mostly due to historical reasons. It has been first implemented by Roman Leshchinskiy in the research group I belong to and is currently providing array functionality to \name{Data Parallel Haskell}, \name{Repa} and \name{Accelerate}, all of which originate from this group.\todo{Accelerate uses Vector?}}

\todo{Perhaps give a simple example of looping using vector. Or else rename the section to something else}

\begin{cfigure}{\label{fig:7-loop-grammar}\Loop language grammar.}
\input{loop-grammar.tex}
\end{cfigure}

\subsection{Th}

\begin{minipage}{\linewidth}
\begin{hscode2}%
      {07-toPercentile-hs}%
      {Generated Haskell code for $toPercentile$ function}
entry :: [Dynamic] -> Dynamic
entry [!arr_xs] = toDyn (run (fd arr_xs))

run :: Vector Int -> Vector Int
run !arr_xs = runST (init_ys arr_xs)

init_ys !arr_xs
  = do let !ix_xs = 0;
       let !len_xs = lengthArray arr_xs;
       let !len_ys = len_xs;
       !arr_ys <- newArray len_ys;
       guard_ys arr_xs arr_ys len_xs ix_xs

guard_ys !arr_xs !arr_ys !len_xs !ix_xs
  = do let !pred_xs = (<) ix_xs len_xs;
       let !ix_ys = ix_xs;
       if pred_xs
        then do body_ys arr_xs arr_ys len_xs ix_xs ix_ys
        else done_ys arr_xs arr_ys len_xs ix_xs ix_ys

body_ys !arr_xs !arr_ys !len_xs !ix_xs !ix_ys
  = do let !elt_xs = readArray ix_xs arr_xs;
       let !f_ys = \a -> (*) a (fromInteger 100);
       let !elt_ys = f_ys elt_xs;
       write_ys arr_xs arr_ys len_xs ix_xs ix_ys elt_ys

write_ys !arr_xs !arr_ys !len_xs !ix_xs !ix_ys !elt_ys
  = do writeArray arr_ys ix_ys elt_ys;
       bottom_ys arr_xs arr_ys len_xs ix_xs ix_ys elt_ys

bottom_ys !arr_xs !arr_ys !len_xs !ix_xs !ix_ys !elt_ys
  = do let !one_xs = 1;
       let !ix_xs' = (+) ix_xs one_xs;
       guard_ys arr_xs arr_ys len_xs ix_xs'

done_ys !arr_xs !arr_ys !len_xs !ix_xs !ix_ys
  = do !result <- sliceArray arr_ys ix_ys;
       return result
\end{hscode2}
\end{minipage}

\subsection{Internal optimisations}
\subsubsection{Liveness analysis}
\subsubsection{Generating}


\subsubsection{Looping}
\begin{itemize}
\item There are many ways a loop can be represented in code
\item FPrs see it as a recursive function
\item Procedural programmers see it as a while or for C loop
\item Down at the machine level it is a chunk of code with a label and jump statement to the beginning of the loop (or alternatively out of the loop)
\item GPGPU
\item Vectorised instructions
\item When generating HsCode only rec fun, however want fast machine code in the end
\item Tail rec
\item Give example of what machine code it becomes
\item Thus need to make sure we always have tail rec
\end{itemize}

\subsection{Hell}

\begin{itemize}
\item haskell via TH (slow codegen, all native, TH is helpful, easy to gen code and parametrising functions, use the excellent GHC optimiser)
\item external (c) (slow codegen, fast exec, how to identify function correspondence, must act as compiler)
\item llvm (fast inmem gen, low level, must act as compiler in many ways)

\end {itemize}


\subsection{Haskell code generation}

\subsubsection{What do we need to generate}
\begin{itemize}
\item Loop code
\item A plugin template
\item Interface glue
\item Arg passing to and from - variadic functions, can't do without tricks
\item Lists of args + Unsafe coerce
\end{itemize}

\subsubsection{Efficient numeric computations in Haskell}
\begin{itemize}
\item Talk about haskell data structures (lists, arrays)
\item about boxed values
\item Prohibitive performance costs
\item Unboxed values
\end{itemize}

\subsubsection{Mutable vectors}
\begin{itemize}
\item Very low level access
\item Haskell vector or GHC.Prim
\item Largely the same underneath
\item Vector may be more intuitive
\item Offers many types of vectors and levels of access to them
\item Uses ST monad, to make sure...
\end{itemize}


\subsection{GHC provided optimisations}
\subsubsection{Tail recursion}
\begin{itemize}
\item Perhaps put the points from above here
\end{itemize}

\subsubsection{Strictness}
\begin{itemize}
\item What is it and why
\item Strictness analysis example
\item Where in our case it would fail
\item What to do: two things, the easiest is !
\end{itemize}

\subsubsection{Inlining}
\begin{itemize}
\item Funcall costs
\item Perhaps give an example with benchmark
\item LLVM helps?
\end{itemize}

\subsubsection{Unboxing}
\begin{itemize}
\item Give example
\item Rewrite \texttt{case i\# of I\# ->} which rewrites
\item (Might wanna merge with the section above)
\end{itemize}




\subsubsection{Compilation and loading}
\begin{itemize}
\item GHC API
\end{itemize} 


\subsection{Background}

\subsubsection{Passing loop state}

\begin{itemize}
\item We were passing explicit args
\item fast, GHC knows how to optimise away unused/dup variables (of which we have a lot)
\item STRef/IORefs - convenient but they are boxed and are not inlined even though are programs are strict
\item State monad. Build State monad on top of ST, use tuples for multiple state variables. It inlines and unboxes everything alright, but for some reason there remain lazy lets and continuation.
\item Arguably the cleanest approach to unboxed mutable state. Removes the limitation outlined in () whereby the updated value of the assigned variable won't be available in the same block it's assigned. It would also make the internal compilation process cleaner. Right now it needs to generate a fresh variable name for the updated variable and keep track of the variables updated in the current block.
\end{itemize}

\end{document}